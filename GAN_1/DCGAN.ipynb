{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d88214-a03a-4ce7-ae03-bbd7df950d53",
   "metadata": {},
   "source": [
    "## Deep Convolutional Generative Adversarial Networks (DCGANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb5bb9-452c-4c95-9210-25b0dd0c7e00",
   "metadata": {},
   "source": [
    "Deep Convolutional Generative Adversarial Networks (DCGANs) combine the power of deep convolutional neural networks (CNNs) with adversarial training to generate high-quality images from random noise. DCGANs have applications in image synthesis, style transfer, and data augmentation. In this tutorial, we explore DCGAN architecture and implementation, focusing on the popular MNIST dataset for digit generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e663b-6af8-4bae-956b-8d631c449655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d25db650-9d22-4ff8-860d-c1d2e3f5c89c",
   "metadata": {},
   "source": [
    "Import Tensorflow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a129cf3f-d3d6-4f98-8e01-b1d4a99daed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tjmah\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404ce968-0172-4901-8e2d-686046459b5c",
   "metadata": {},
   "source": [
    "Download MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15703426-5ba8-4d81-ba80-222c205dc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "364ff92d-4e32-49d9-83b7-e09250b70545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train images =  60000\n",
      "Length of train labels =  60000\n",
      "Train_mages shape =  (60000, 28, 28, 1)\n",
      "Data type =  float32\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train images = \", len(train_images))\n",
    "print(\"Length of train labels = \", len(train_labels))\n",
    "print(\"Train_mages shape = \", train_images.shape)\n",
    "print(\"Data type = \", train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffda452-94a2-44aa-8a75-d89055307bea",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNNs) typically expect input data in the shape of [batch_size, height, width, channels]. Reshaping allows to rearrange the dimensions of the dataset to match the required input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad1a6446-d236-45a7-a44f-1eb03d6549ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_mages new shape =  (60000, 28, 28, 1)\n",
      "Data type =  float32\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1) #.astype('float32')\n",
    "print(\"Train_mages new shape = \", train_images.shape)\n",
    "print(\"Data type = \", train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659df66-2e60-49c9-8830-50be3bb6779c",
   "metadata": {},
   "source": [
    " BUFFER_SIZE typically refers to the number of elements (samples) from the dataset that should be buffered (or shuffled) at a time. When you're dealing with large datasets that cannot fit entirely into memory, you can't shuffle the entire dataset at once. Instead, you shuffle a buffer of elements. Setting the BUFFER_SIZE parameter controls the size of this buffer. A larger buffer size allows for more effective shuffling but requires more memory.\n",
    "\n",
    " BATCH_SIZE refers to the number of samples that are propagated through the neural network in a single forward/backward pass. In other words, it's the number of samples processed before the model's parameters are updated. Using mini-batches instead of processing the entire dataset at once helps in reducing the memory usage and allows for faster training as computations can be parallelized across the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9505fe72-233b-48fd-87fa-6e53f17f5a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc46206-6e72-42c1-bf09-523b543b0a76",
   "metadata": {},
   "source": [
    "tf.data.Dataset.from_tensor_slices(train_images): \n",
    ">This creates a TensorFlow dataset from the train_images data. The train_images variable is a tensor/array containing the training data. Each element of train_images is treated as a separate sample along the first dimension.\n",
    "\n",
    ".shuffle(BUFFER_SIZE): \n",
    "> This shuffles the elements of the dataset with a buffer size of BUFFER_SIZE. Shuffling the dataset is important during training to prevent the model from learning spurious correlations due to the order of the training data. The BUFFER_SIZE parameter determines the number of elements from which the dataset is shuffled at once. A larger buffer size allows for more effective shuffling but requires more memory.\n",
    "\n",
    ".batch(BATCH_SIZE): \n",
    "> This groups the elements of the dataset into batches of size BATCH_SIZE. Batching is done to improve computational efficiency by processing multiple samples in parallel. The BATCH_SIZE parameter specifies the number of elements in each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a822437-0982-43ad-8cd3-a52d8d5d0694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37d8608f-3ed9-491d-aa6c-28d861af90f5",
   "metadata": {},
   "source": [
    "### Create the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153365d-77a9-40d1-ab67-f1d746d7f440",
   "metadata": {},
   "source": [
    "#### The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c90d31-6108-430d-a590-c6142bcb319f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0130c9d5-0ada-4f3a-aa02-e4e18a2e2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82191dd1-7d91-4392-bdae-613d09aebffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccab620-bda9-4840-9d8b-f66aca4f6b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6ad8d-eca7-4fc5-914f-f9b108a6399f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb5d166-9d17-48d3-a953-1e85e731244b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8b8a9-9569-4717-a7c3-7a2c5220de80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94243b-299b-4475-b73e-18a760f13802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c9ee40-8657-4332-b5de-1c1e75ed7336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
