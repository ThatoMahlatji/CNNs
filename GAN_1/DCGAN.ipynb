{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d88214-a03a-4ce7-ae03-bbd7df950d53",
   "metadata": {},
   "source": [
    "## Deep Convolutional Generative Adversarial Networks (DCGANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb5bb9-452c-4c95-9210-25b0dd0c7e00",
   "metadata": {},
   "source": [
    "Deep Convolutional Generative Adversarial Networks (DCGANs) combine the power of deep convolutional neural networks (CNNs) with adversarial training to generate high-quality images from random noise. DCGANs have applications in image synthesis, style transfer, and data augmentation. In this tutorial, we explore DCGAN architecture and implementation, focusing on the popular MNIST dataset for digit generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e663b-6af8-4bae-956b-8d631c449655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d25db650-9d22-4ff8-860d-c1d2e3f5c89c",
   "metadata": {},
   "source": [
    "Import Tensorflow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a129cf3f-d3d6-4f98-8e01-b1d4a99daed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tjmah\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404ce968-0172-4901-8e2d-686046459b5c",
   "metadata": {},
   "source": [
    "Download MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15703426-5ba8-4d81-ba80-222c205dc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "364ff92d-4e32-49d9-83b7-e09250b70545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train images =  60000\n",
      "Length of train labels =  60000\n",
      "Train_mages shape =  (60000, 28, 28, 1)\n",
      "Data type =  float32\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train images = \", len(train_images))\n",
    "print(\"Length of train labels = \", len(train_labels))\n",
    "print(\"Train_mages shape = \", train_images.shape)\n",
    "print(\"Data type = \", train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffda452-94a2-44aa-8a75-d89055307bea",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNNs) typically expect input data in the shape of [batch_size, height, width, channels]. Reshaping allows to rearrange the dimensions of the dataset to match the required input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad1a6446-d236-45a7-a44f-1eb03d6549ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_mages new shape =  (60000, 28, 28, 1)\n",
      "Data type =  float32\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1) #.astype('float32')\n",
    "print(\"Train_mages new shape = \", train_images.shape)\n",
    "print(\"Data type = \", train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659df66-2e60-49c9-8830-50be3bb6779c",
   "metadata": {},
   "source": [
    " BUFFER_SIZE typically refers to the number of elements (samples) from the dataset that should be buffered (or shuffled) at a time. When you're dealing with large datasets that cannot fit entirely into memory, you can't shuffle the entire dataset at once. Instead, you shuffle a buffer of elements. Setting the BUFFER_SIZE parameter controls the size of this buffer. A larger buffer size allows for more effective shuffling but requires more memory.\n",
    "\n",
    " BATCH_SIZE refers to the number of samples that are propagated through the neural network in a single forward/backward pass. In other words, it's the number of samples processed before the model's parameters are updated. Using mini-batches instead of processing the entire dataset at once helps in reducing the memory usage and allows for faster training as computations can be parallelized across the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9505fe72-233b-48fd-87fa-6e53f17f5a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc46206-6e72-42c1-bf09-523b543b0a76",
   "metadata": {},
   "source": [
    "tf.data.Dataset.from_tensor_slices(train_images): \n",
    ">This creates a TensorFlow dataset from the train_images data. The train_images variable is a tensor/array containing the training data. Each element of train_images is treated as a separate sample along the first dimension.\n",
    "\n",
    ".shuffle(BUFFER_SIZE): \n",
    "> This shuffles the elements of the dataset with a buffer size of BUFFER_SIZE. Shuffling the dataset is important during training to prevent the model from learning spurious correlations due to the order of the training data. The BUFFER_SIZE parameter determines the number of elements from which the dataset is shuffled at once. A larger buffer size allows for more effective shuffling but requires more memory.\n",
    "\n",
    ".batch(BATCH_SIZE): \n",
    "> This groups the elements of the dataset into batches of size BATCH_SIZE. Batching is done to improve computational efficiency by processing multiple samples in parallel. The BATCH_SIZE parameter specifies the number of elements in each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a822437-0982-43ad-8cd3-a52d8d5d0694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37d8608f-3ed9-491d-aa6c-28d861af90f5",
   "metadata": {},
   "source": [
    "### Create the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153365d-77a9-40d1-ab67-f1d746d7f440",
   "metadata": {},
   "source": [
    "#### The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c90d31-6108-430d-a590-c6142bcb319f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0130c9d5-0ada-4f3a-aa02-e4e18a2e2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    ###--- Model Creation ---###\n",
    "    model = tf.keras.Sequential()\n",
    "    # This initializes a sequential model, which is a linear stack of layers.\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    # This adds a dense (fully connected) layer to the model with 7*7*256 neurons (flattened to a 2D array).\n",
    "    #-- The input shape for this layer is (100,), indicating that it takes a 100-dimensional input vector.\n",
    "    #-- This likely receives a 100-dimensional noise vector as input.\n",
    "    #--- The 'use_bias=False' argument skips adding a bias term which can improve performance in certain GAN scenarios.\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # This adds a batch normalization layer. \n",
    "    #- Batch normalization normalizes the activations of the previous layer at each batch, helping the training process.\n",
    "    #-- improving training stability.\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # This adds a Leaky ReLU activation function.\n",
    "    #- allows a small, non-zero gradient when the unit is not active, which helps prevent the \"dying ReLU\" problem.\n",
    "    #-- allowing small non-zero gradients even for negative inputs.\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    # This reshapes the output of the previous layer into a 3D tensor with shape (7, 7, 256).\n",
    "    #- likely representing a feature map.\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "    # This assertion checks if the shape of the output tensor is as expected.\n",
    "    \n",
    "    ###--- Deconvolutional layers ---###\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    # Conv2DTranspose - essentially deconvolutional (transposed convolutional) layers that upsample the spatial dimensions of the feature map.\n",
    "    #-  with 128 filters, a kernel size of (5, 5), and a stride of (1, 1). \n",
    "    #-- The padding is set to 'same': ensures the output size remains the same after convolution.\n",
    "    #--- bias usage is set to False.\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    # checks the shape of the output tensor after adding the convolutional layer.\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # Adds another batch normalization layer.\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # Leaky ReLU continues to be used as the activation function.\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    # Conv2DTranspose - essentially deconvolutional (transposed convolutional) layers that upsample the spatial dimensions of the feature map.\n",
    "    #-  with 64 filters, a kernel size of (5, 5), and a stride of (2, 2). \n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # Adds another batch normalization layer.\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # Leaky ReLU continues to be used as the activation function.\n",
    "\n",
    "    ###--- Final layer ---###\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    # adds a transposed convolutional layer with a single filter (as the output should be grayscale),\n",
    "    #- a kernel size of (5, 5), a stride of (2, 2) for upsampling and 'tanh' activation function.\n",
    "    #-- Tanh is used to ensure the output values are in the range [-1, 1], suitable for image pixel values.\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    # checks the final shape of the output tensor, ensuring it has the desired dimensions for a 28x28 grayscale image.\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c3184d-01b0-4610-abf1-be9a0bf95bdd",
   "metadata": {},
   "source": [
    "This generator model takes a 100-dimensional noise vector as input and generates a 28x28 grayscale image as output. It gradually upsamples the input noise through transposed convolutional layers (deconvolutional layers), batch normalization, and activation functions to produce an image that resembles the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82191dd1-7d91-4392-bdae-613d09aebffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fccab620-bda9-4840-9d8b-f66aca4f6b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27d76088150>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "# It generates 100 random numbers using the normal distribution (mean=0, standard deviation=1).\n",
    "#- These numbers are then placed in a single array (tensor) with a shape of [1, 100].\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
    "# Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6ad8d-eca7-4fc5-914f-f9b108a6399f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d946eeb-47b8-4d50-b750-f47da36df2a8",
   "metadata": {},
   "source": [
    "#### The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8b8a9-9569-4717-a7c3-7a2c5220de80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c0002f0-f77c-453c-ab91-0133360aa64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166e042-e4fc-459a-bbd8-c88c1cc0965d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c94243b-299b-4475-b73e-18a760f13802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00199609]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c9ee40-8657-4332-b5de-1c1e75ed7336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
